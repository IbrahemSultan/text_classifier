{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bfb8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "plt.style.use(style=\"seaborn\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0634d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4187ddb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef8b6702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea028ff",
   "metadata": {},
   "source": [
    "data in each class\n",
    "\n",
    "id        7613 (non-null)\n",
    "\n",
    "keyword   7552\n",
    "\n",
    "location  5080\n",
    "\n",
    "text      7613 (non-null)\n",
    "\n",
    "target    7613 (non-null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "264f58e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54700f8f",
   "metadata": {},
   "source": [
    "there is missing data is keyword by 61 null (0.8%)\n",
    "\n",
    "and in location 2533 missing or null value (33.27%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e21e022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatalities     45\n",
       "deluge         42\n",
       "armageddon     42\n",
       "damage         41\n",
       "body%20bags    41\n",
       "sinking        41\n",
       "harm           41\n",
       "evacuate       40\n",
       "twister        40\n",
       "collided       40\n",
       "siren          40\n",
       "windstorm      40\n",
       "fear           40\n",
       "outbreak       40\n",
       "hellfire       39\n",
       "Name: keyword, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the top 15 keyword of the data\n",
    "x = df[\"keyword\"].value_counts()\n",
    "x.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee674b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA                104\n",
       "New York            71\n",
       "United States       50\n",
       "London              45\n",
       "Canada              29\n",
       "Nigeria             28\n",
       "UK                  27\n",
       "Los Angeles, CA     26\n",
       "India               24\n",
       "Mumbai              22\n",
       "Washington, DC      21\n",
       "Kenya               20\n",
       "Worldwide           19\n",
       "Australia           18\n",
       "Chicago, IL         18\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the top 15 locations of the data\n",
    "y = df[\"location\"].value_counts()\n",
    "y.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd869e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the target of the data\n",
    "w = df[\"target\"].value_counts()\n",
    "w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb67d797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     Our Deeds are the Reason of this #earthquake M...\n",
       "1                Forest fire near La Ronge Sask. Canada\n",
       "2     All residents asked to 'shelter in place' are ...\n",
       "3     13,000 people receive #wildfires evacuation or...\n",
       "4     Just got sent this photo from Ruby #Alaska as ...\n",
       "...                                                 ...\n",
       "7608  Two giant cranes holding a bridge collapse int...\n",
       "7609  @aria_ahrary @TheTawniest The out of control w...\n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...\n",
       "7611  Police investigating after an e-bike collided ...\n",
       "7612  The Latest: More Homes Razed by Northern Calif...\n",
       "\n",
       "[7613 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_text = df.drop(['id','keyword','location','target'],axis=1)\n",
    "file_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b86fec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    7613 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 59.6+ KB\n"
     ]
    }
   ],
   "source": [
    "file_text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a839a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = file_text.sum(axis=1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf90f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_cell = num_columns.values.sum(axis=0)\n",
    "#one_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1580f38",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eb9ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "    return url.sub(r\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e59e215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    html = re.compile(r\"<.*?>\")\n",
    "    return html.sub(r\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9afd3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39765c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df.text.map(lambda x: remove_URL(x))\n",
    "df[\"text\"] = df.text.map(lambda x: remove_html(x))\n",
    "df[\"text\"] = df.text.map(lambda x: remove_punct(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3e73b9",
   "metadata": {},
   "source": [
    "# remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75b1e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    temp_list=[]\n",
    "    for word in text.split():\n",
    "        if word.lower() not in stopwords:\n",
    "            temp_list.append(word.lower())\n",
    "    return \" \".join(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a39c6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab28fcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            deeds reason earthquake may allah forgive us\n",
      "1                   forest fire near la ronge sask canada\n",
      "2       residents asked shelter place notified officer...\n",
      "3       13000 people receive wildfires evacuation orde...\n",
      "4       got sent photo ruby alaska smoke wildfires pou...\n",
      "                              ...                        \n",
      "7608    two giant cranes holding bridge collapse nearb...\n",
      "7609    ariaahrary thetawniest control wild fires cali...\n",
      "7610                      m194 0104 utc5km volcano hawaii\n",
      "7611    police investigating ebike collided car little...\n",
      "7612    latest homes razed northern california wildfir...\n",
      "Name: text, Length: 7613, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7ff217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def counter(text):\n",
    "    count = Counter()\n",
    "    for i in text.values:\n",
    "        for word in i.split():\n",
    "            count[word] +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c2a6a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('like', 345), ('im', 299), ('amp', 298), ('fire', 250), ('get', 229), ('new', 224), ('via', 220), ('people', 196), ('one', 193), ('news', 193)]\n"
     ]
    }
   ],
   "source": [
    "#print the most common words\n",
    "text = df.text\n",
    "count_words = counter(text)\n",
    "print(count_words. most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f30a08b",
   "metadata": {},
   "source": [
    "like, fire, get, via, people, new, one and news are the most common word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d294d229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 2575), ('a', 1845), ('to', 1805), ('in', 1757), ('of', 1722), ('and', 1302), ('I', 1197), ('for', 820), ('is', 814), ('on', 773)]\n"
     ]
    }
   ],
   "source": [
    "#print the most common stop words\n",
    "text = num_columns\n",
    "count_stop_words = counter(text)\n",
    "print(count_stop_words.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d7498ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17971"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max_length = 26 old # 255 guaranteed \n",
    "\n",
    "num_words = len(count_words)\n",
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8ed8d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_length = max(len(x) for x in df.text)\n",
    "max_length =20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6422c",
   "metadata": {},
   "source": [
    "# Install NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f4d108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53ca1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74499c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78a6c03",
   "metadata": {},
   "source": [
    "# df Test Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcaba38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "182a866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ceb8b1",
   "metadata": {},
   "source": [
    "# Train - Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a9d88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(df.shape[0] * 0.7)\n",
    "\n",
    "train_text = df.text[:train_size]\n",
    "train_target = df.target[:train_size]\n",
    "\n",
    "test_text = df.text[train_size:]\n",
    "test_target = df.target[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbb9e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5ed28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "#word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4c99581",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = tokenizer.texts_to_sequences(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4415d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "train_padded = pad_sequences(\n",
    "    train_text, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aabc364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = tokenizer.texts_to_sequences(test_text)\n",
    "test_padded = pad_sequences(\n",
    "    test_text, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8615cf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (5329, 20)\n",
      "Shape of test (2284, 20)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of train {train_padded.shape}\")\n",
    "print(f\"Shape of test {test_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14883d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.initializers import Constant\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(num_words, 32, input_length=max_length))\n",
    "model.add(LSTM(64, dropout=0.1))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=3e-4)\n",
    "model.compile(loss=\"binary_crossentropy\", \n",
    "              optimizer=optimizer, \n",
    "              metrics=[\"accuracy\"]\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "411619d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 32)            575072    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 599,969\n",
      "Trainable params: 599,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7786bab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "167/167 [==============================] - 7s 26ms/step - loss: 0.6610 - accuracy: 0.5960 - val_loss: 0.5820 - val_accuracy: 0.7316\n",
      "Epoch 2/5\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.3956 - accuracy: 0.8307 - val_loss: 0.5241 - val_accuracy: 0.7553\n",
      "Epoch 3/5\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.2411 - accuracy: 0.9077 - val_loss: 0.5651 - val_accuracy: 0.7404\n",
      "Epoch 4/5\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 0.1532 - accuracy: 0.9469 - val_loss: 0.6904 - val_accuracy: 0.7246\n",
      "Epoch 5/5\n",
      "167/167 [==============================] - 4s 22ms/step - loss: 0.1033 - accuracy: 0.9662 - val_loss: 0.8605 - val_accuracy: 0.7211\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_padded, train_target, epochs=5, validation_data=(test_padded, test_target),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94f29da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 1s 5ms/step - loss: 0.0619 - accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate(train_padded,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77badbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a91a6c",
   "metadata": {},
   "source": [
    "# Making the Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"text\"] = df_test.text.map(lambda x: remove_URL(x))\n",
    "df_test[\"text\"] = df_test.text.map(lambda x: remove_html(x))\n",
    "df_test[\"text\"] = df_test.text.map(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0589cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sequences = tokenizer.texts_to_sequences(df_test[\"text\"])\n",
    "df_test_padded = pad_sequences(\n",
    "    df_test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab80353",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of test {df_test_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09610be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4febbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75312d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/Cast' defined at (most recent call last):\n    File \"C:\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n      app.start()\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n      result = self._run_cell(\n    File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-45-3181e078c014>\", line 1, in <module>\n      test_prediction = model.predict(x)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 571, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 671, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'sequential/Cast'\nCast string to float is not supported\n\t [[{{node sequential/Cast}}]] [Op:__inference_predict_function_9910]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-3181e078c014>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/Cast' defined at (most recent call last):\n    File \"C:\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n      app.start()\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"C:\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n      result = self._run_cell(\n    File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-45-3181e078c014>\", line 1, in <module>\n      test_prediction = model.predict(x)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 571, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"C:\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 671, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'sequential/Cast'\nCast string to float is not supported\n\t [[{{node sequential/Cast}}]] [Op:__inference_predict_function_9910]"
     ]
    }
   ],
   "source": [
    "test_prediction = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(files['sample'])\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48368ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b70356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f51617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20037207",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train','test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd473a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train','test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21ad405",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80377d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
